{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the values from the environment\n",
    "SAGEMAKER_ACCESS_KEY = os.getenv('SAGEMAKER_ACCESS_KEY')\n",
    "SAGEMAKER_SECRET_KEY = os.getenv('SAGEMAKER_SECRET_KEY')\n",
    "SAGEMAKER_ROLE= os.getenv('SAGEMAKER_ROLE')\n",
    "region_name = 'us-east-1'\n",
    "\n",
    "# Create a boto3 session with the provided credentials\n",
    "boto3_session = boto3.Session(\n",
    "    aws_access_key_id=SAGEMAKER_ACCESS_KEY,\n",
    "    aws_secret_access_key=SAGEMAKER_SECRET_KEY,\n",
    "    REGION_NAME=region_name\n",
    ")\n",
    "\n",
    "# Create a SageMaker client using boto3 with the correct region\n",
    "sm_boto3 = boto3.client('sagemaker', REGION_NAME=region_name)\n",
    "\n",
    "# Create a SageMaker session\n",
    "session = sagemaker.Session(boto_session=boto3_session)\n",
    "\n",
    "# Get the AWS region from the session (should match the specified region)\n",
    "# region = session.boto_session.REGION_NAME\n",
    "\n",
    "# Define the S3 bucket name\n",
    "BUCKET = 'sagemakermlops'\n",
    "\n",
    "# Print the region and bucket name\n",
    "print(f\"Region: {region_name}\")\n",
    "print(f\"Bucket: {BUCKET}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your .env file should be configured with the following:\n",
    "\n",
    "```bash\n",
    "SAGEMAKER_ACCESS_KEY=YourInfoHere\n",
    "SAGEMAKER_SECRET_KEY=YourInfoHere\n",
    "SAGEMAKER_ROLE=YourInfoHere\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Low_Risk','High_Risk], [0,1]\n",
    "df['price_range'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = features.pop(-1)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[features]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.DataFrame(X_train)\n",
    "trainX[label] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test)\n",
    "testX[label] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv('data/train-V-1.csv', index=False)\n",
    "testX.to_csv('data/test-V-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3 for Sagemaker\n",
    "sk_prefix = 'sagemaker/mobile_price_classification/sklearncontainer'\n",
    "trainpath = session.upload_data(\n",
    "    path='data/train-V-1.csv', \n",
    "    bucket=bucket,\n",
    "    key_prefix=sk_prefix\n",
    ")\n",
    "\n",
    "testpath = session.upload_data(\n",
    "    path='data/test-V-1.csv', \n",
    "    bucket=bucket,\n",
    "    key_prefix=sk_prefix\n",
    ")\n",
    "print(trainpath)\n",
    "print(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, 'model.joblib'))\n",
    "    return clf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('[INFO] Extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters sent by the client are passed as command-line arguments\n",
    "    parser.add_argument('--n_estimators', type=int, default=100)\n",
    "    parser.add_argument('--random_state', type=int, default=42)\n",
    "    \n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument('--train-file', type=str, default=\"train-V-1.csv\")\n",
    "    parser.add_argument('--test-file', type=str, default=\"test-V-1.csv\")\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(f'Sklearn Version: {sklearn.__version__}')\n",
    "    print(f'Joblib Version: {joblib.__version__}')\n",
    "    \n",
    "    print('[INFO] Reading data')\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    features = train_df.columns.tolist()\n",
    "    label = features.pop(-1)\n",
    "    \n",
    "    print('Building training and testing datasets')\n",
    "    print()\n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    y_train = train_df[label]\n",
    "    y_test = test_df[label]\n",
    "    \n",
    "    print('Column order:')\n",
    "    print(features)\n",
    "    print()\n",
    "    \n",
    "    print('Data Shape:')\n",
    "    print()\n",
    "    print('---- SHAPE OF TRAINING DATA ----')\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print()\n",
    "    print('---- SHAPE OF TESTING DATA ----')\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print()\n",
    "    \n",
    "    print('Training RandomForest Model....')\n",
    "    print()\n",
    "    model = RandomForestClassifier(n_estimators=args.n_estimators, random_state=args.random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    print()\n",
    "    \n",
    "    model_path = os.path.join(args.model_dir, 'model.joblib')\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f'Model persisted at {model_path}')\n",
    "    print()\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_rep = classification_report(y_test, y_pred_test)\n",
    "    \n",
    "    print()\n",
    "    print('---- METRICS RESULTS FOR TESTING DATA ----')\n",
    "    print()\n",
    "    print(f'Total Rows are: {X_test.shape[0]}')\n",
    "    print(f'[TESTING] Model Accuracy is: {test_acc}')\n",
    "    print(test_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION='0.23-1'\n",
    "\n",
    "sklearn_estimator= SKLearn(\n",
    "    entry_point='script.py',\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name='RF-custom-sklearn',\n",
    "    hyperparameters={\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 0\n",
    "    },\n",
    "    use_spot_instance = True,\n",
    "    max_wait = 7200,\n",
    "    max_run = 3600,\n",
    "    sagemaker_session=session \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)\n",
    "# sklearn_estimator.fit({\"train\": datapathh}, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
